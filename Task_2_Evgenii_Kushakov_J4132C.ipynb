{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6884dcb8-fa6c-4411-888e-0c280d88543a",
   "metadata": {},
   "source": [
    "1. Download Alice in Wonderland by Lewis Carroll from Project Gutenberg's website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33080f5c-eb2c-4b64-83ba-966d425ed203",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://www.gutenberg.org/files/11/11-0.txt\"\n",
    "response = requests.get(url)\n",
    "response.encoding = 'utf-8'\n",
    "text = response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607e42f1-b40e-494d-b1aa-eab871f1dc21",
   "metadata": {},
   "source": [
    "2. Perform any necessary preprocessing on the text, including converting to lower case, removing stop words, numbers / non-alphabetic characters, lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "448e3721-474f-41d2-a57d-e0cb09406217",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Remove HTML tags using BeautifulSoup\n",
    "text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "text = text.replace('XII.', '12.')\n",
    "text = text.replace('XI.', '11.')\n",
    "text = text.replace('IX.', '9.')\n",
    "text = text.replace('VIII.', '8.')\n",
    "text = text.replace('VII.', '7.')\n",
    "text = text.replace('VI.', '6.')\n",
    "text = text.replace('IV.', '4.')\n",
    "text = text.replace('X.', '10.')\n",
    "text = text.replace('V.', '5.')\n",
    "text = text.replace('III.', '3.')\n",
    "text = text.replace('II.', '2.')\n",
    "text = text.replace('I.', '1.')\n",
    "\n",
    "# Tokenize the text\n",
    "words = word_tokenize(text)\n",
    "\n",
    "# Convert to lowercase and remove non-alphabetic characters\n",
    "words = [word.lower() for word in words if word.isalpha()]\n",
    "\n",
    "# Remove stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "words = [word for word in words if word not in stop_words]\n",
    "\n",
    "# Lemmatize the words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "words = [lemmatizer.lemmatize(word) for word in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc2e8de-7879-447f-aa2a-a7c156fa08fc",
   "metadata": {},
   "source": [
    "3. Find the top 10 important words for each chapter and name the chapters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6718a29-aeb4-4d37-b0ac-5d8fe6f860fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 1: alice little way like see think door said one could\n",
      "['alice', 'little', 'way', 'like', 'see', 'think', 'door', 'said', 'one', 'could']\n",
      "Chapter 2: alice mouse little said go dear thing foot thought must\n",
      "['alice', 'mouse', 'little', 'said', 'go', 'dear', 'thing', 'foot', 'thought', 'must']\n",
      "Chapter 3: said alice mouse dodo know one soon lory long bird\n",
      "['said', 'alice', 'mouse', 'dodo', 'know', 'one', 'soon', 'lory', 'long', 'bird']\n",
      "Chapter 4: alice little rabbit said one bill thought sure heard get\n",
      "['alice', 'little', 'rabbit', 'said', 'one', 'bill', 'thought', 'sure', 'heard', 'get']\n",
      "Chapter 5: said alice caterpillar serpent pigeon well little minute think size\n",
      "['said', 'alice', 'caterpillar', 'serpent', 'pigeon', 'well', 'little', 'minute', 'think', 'size']\n",
      "Chapter 6: said alice cat like little duchess much footman would baby\n",
      "['said', 'alice', 'cat', 'like', 'little', 'duchess', 'much', 'footman', 'would', 'baby']\n",
      "Chapter 7: said alice hatter dormouse march hare time thing well one\n",
      "['said', 'alice', 'hatter', 'dormouse', 'march', 'hare', 'time', 'thing', 'well', 'one']\n",
      "Chapter 8: said alice queen head king three cat went one hedgehog\n",
      "['said', 'alice', 'queen', 'head', 'king', 'three', 'cat', 'went', 'one', 'hedgehog']\n",
      "Chapter 9: said alice turtle mock gryphon duchess queen went never little\n",
      "['said', 'alice', 'turtle', 'mock', 'gryphon', 'duchess', 'queen', 'went', 'never', 'little']\n",
      "Chapter 10: said gryphon turtle alice mock would lobster dance soup beautiful\n",
      "['said', 'gryphon', 'turtle', 'alice', 'mock', 'would', 'lobster', 'dance', 'soup', 'beautiful']\n",
      "Chapter 11: said king hatter alice court dormouse one queen witness thought\n",
      "['said', 'king', 'hatter', 'alice', 'court', 'dormouse', 'one', 'queen', 'witness', 'thought']\n",
      "Chapter 12: said alice king would queen little jury white rabbit one\n",
      "['said', 'alice', 'king', 'would', 'queen', 'little', 'jury', 'white', 'rabbit', 'one']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "\n",
    "# Split the text into chapters\n",
    "chapters = re.split(r'chapter', ' '.join(words))\n",
    "last_chapter = chapters[-1]\n",
    "chapters[-1] = ' end '.join(last_chapter.split(' end ')[0:2])\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10)\n",
    "\n",
    "chapter_names = []\n",
    "top_words_per_chapter = []\n",
    "\n",
    "# Process each chapter\n",
    "for i, chapter in enumerate(chapters[13:]): \n",
    "    chapter_vector = tfidf_vectorizer.fit_transform([chapter])\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "    \n",
    "    # Sort and get top 10 words by TF-IDF score\n",
    "    sorted_words = [feature_names[i] for i in chapter_vector.toarray().argsort()[0][::-1][:10]]\n",
    "    \n",
    "    # Naming chapters using top words\n",
    "    chapter_name = f\"Chapter {i + 1}: {' '.join(sorted_words)}\"\n",
    "    chapter_names.append(chapter_name)\n",
    "    top_words_per_chapter.append(sorted_words)\n",
    "\n",
    "# Print chapter names and top words\n",
    "for i, chapter_name in enumerate(chapter_names):\n",
    "    print(chapter_name)\n",
    "    print(top_words_per_chapter[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc8fe4f-df3b-45d2-83f5-34d6865e3d79",
   "metadata": {},
   "source": [
    "4. Find the Top 10 most used verbs in sentences with Alice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7be77a3c-ad41-4d6a-a781-89080fd41bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 verbs used with Alice:\n",
      "said: 254\n",
      "thought: 50\n",
      "went: 41\n",
      "know: 37\n",
      "say: 33\n",
      "looked: 31\n",
      "see: 31\n",
      "got: 27\n",
      "think: 25\n",
      "began: 25\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "\n",
    "# Tokenize sentences\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "# Find sentences containing \"Alice\" and extract verbs\n",
    "alice_verbs = []\n",
    "for sentence in sentences:\n",
    "    if \"Alice\" in sentence:\n",
    "        words = word_tokenize(sentence)\n",
    "        tagged_words = nltk.pos_tag(words)\n",
    "        verbs = [word for word, pos in tagged_words if pos.startswith(\"V\") and word.isalpha() and word not in stop_words]\n",
    "        alice_verbs.extend(verbs)\n",
    "\n",
    "# Count verb occurrences\n",
    "verb_counts = Counter(alice_verbs)\n",
    "\n",
    "# Get the top 10 most used verbs with Alice\n",
    "top_verbs = verb_counts.most_common(10)\n",
    "\n",
    "# Print the results\n",
    "print(\"Top 10 verbs used with Alice:\")\n",
    "for verb, count in top_verbs:\n",
    "    print(f\"{verb}: {count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
